{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG16_only_fl_BW.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IX1HjlVxZtvK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618987759231,"user_tz":-330,"elapsed":1349,"user":{"displayName":"Dwijesh Athrey K","photoUrl":"","userId":"01879196924165953212"}},"outputId":"13bbb0db-118b-4dce-bd00-151fddd79be3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GjinKnTjaHah","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618987759895,"user_tz":-330,"elapsed":2001,"user":{"displayName":"Dwijesh Athrey K","photoUrl":"","userId":"01879196924165953212"}},"outputId":"ee6c3559-878c-4419-ff3f-badd3842dfca"},"source":["%cd drive/MyDrive/Major\\ Project"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1ip9U1PHHqJrfXpdXp5tEPrx29H2d9jH6/Major Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7gNeIAdAIrRB"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import time\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from torchvision import models\n","import os\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import copy\n","import PIL\n","from torchvision import models\n","from PIL import Image\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2HXbcQwIye8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618987759898,"user_tz":-330,"elapsed":1991,"user":{"displayName":"Dwijesh Athrey K","photoUrl":"","userId":"01879196924165953212"}},"outputId":"fefa0069-9b99-4163-f0f4-d8fbc2203e77"},"source":["# check GPU availability\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bxeu9WHVI61x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618987760347,"user_tz":-330,"elapsed":2432,"user":{"displayName":"Dwijesh Athrey K","photoUrl":"","userId":"01879196924165953212"}},"outputId":"17a0c80f-2ff9-47d2-9cf0-a2e1f21c72a6"},"source":["# Data loading (Modiflication required)\n","from torchvision import transforms,datasets\n","transform = transforms.Compose(\n","    [transforms.Resize((224, 224)),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","data_dir = 'ImageDatasets/BnWDataset2/'\n","image_dataset = datasets.ImageFolder(data_dir,transform)\n","total_count = len(image_dataset)\n","train_count = int(0.8 * total_count)\n","test_count = total_count - train_count\n","train_dataset, test_dataset = torch.utils.data.random_split(image_dataset, [train_count, test_count])\n","\n","dataloaders = {'train': torch.utils.data.DataLoader(train_dataset, batch_size=4,\n","                                             shuffle=True, num_workers=4),\n","               'val': torch.utils.data.DataLoader(test_dataset, batch_size=4,\n","                                             shuffle=True, num_workers=4)}\n","dataset_sizes = {'train': len(train_dataset),'val':len(test_dataset)}\n","class_names = image_dataset.classes"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1uj_9lt3JCNU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618987764431,"user_tz":-330,"elapsed":6508,"user":{"displayName":"Dwijesh Athrey K","photoUrl":"","userId":"01879196924165953212"}},"outputId":"256e44b2-9cf0-4315-b4f8-e220cc669cc7"},"source":["# Downloading VGG network\n","vgg16 = models.vgg16(pretrained=True)\n","vgg16.to(device)\n","print(vgg16)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xrIKvDslJNal"},"source":["# Freezing convolution weights\n","for param in vgg16.features.parameters():\n","    param.requires_grad = False\n","# change the number of classes \n","vgg16.classifier = nn.Sequential(\n","    nn.Linear(in_features=25088, out_features=4096, bias=True),\n","    nn.ReLU(inplace=True),\n","    nn.Dropout(p=0.5, inplace=False),\n","    nn.Linear(in_features=4096, out_features=4096, bias=True),\n","    nn.ReLU(inplace=True),\n","    nn.Dropout(p=0.5, inplace=False),\n","    nn.Linear(in_features=4096, out_features=len(class_names), bias=True)\n",")\n","Net = vgg16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMNipxjgJZ5Z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yPj8jm2JdKR"},"source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    try:\n","      for epoch in range(num_epochs):\n","        \n","          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","          print('-' * 10)\n","\n","          for phase in ['train', 'val']:\n","              if phase == 'train':\n","                  scheduler.step()\n","                  model.train()  # Set model to training mode\n","              else:\n","                  model.eval()   # Set model to evaluate mode\n","\n","              running_loss = 0.0\n","              running_corrects = 0\n","\n","              # Iterate over data.\n","              for inputs, labels in dataloaders[phase]:\n","                  inputs = inputs.to(device)\n","                  labels = labels.to(device)\n","\n","                  # zero the parameter gradients\n","                  optimizer.zero_grad()\n","\n","                  # forward\n","                  # track history if only in train\n","                  with torch.set_grad_enabled(phase == 'train'):\n","                      outputs = model(inputs)\n","                      _, preds = torch.max(outputs, 1)\n","                      loss = criterion(outputs, labels)\n","\n","                      # backward + optimize only if in training phase\n","                      if phase == 'train':\n","                          loss.backward()\n","                          optimizer.step()\n","\n","                  # statistics\n","                  running_loss += loss.item() * inputs.size(0)\n","                  running_corrects += torch.sum(preds == labels.data)\n","\n","              epoch_loss = running_loss / dataset_sizes[phase]\n","              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","              print(f\"{phase} Running Corrects:,{running_corrects.double()}\")\n","              print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                  phase, epoch_loss, epoch_acc))\n","\n","              # deep copy the model\n","              if phase == 'val' and epoch_acc > best_acc:\n","                  best_acc = epoch_acc\n","        \n","                  best_model_wts = copy.deepcopy(model.state_dict())\n","          print()\n","    except KeyboardInterrupt:\n","      print('Interrupting Training...')\n","      print()\n","      model.load_state_dict(best_model_wts)  \n","      if epoch<1:\n","        return model    \n","\n","    model.load_state_dict(best_model_wts)  \n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    #model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdBidR_DJhnl"},"source":["def ConfMat(model,data = 'val'):\n","  since=time.time()\n","  confusionMatrix=np.zeros((len(class_names),len(class_names)),dtype=int)\n","  with torch.no_grad():\n","      for data in dataloaders[data]:\n","          images, labels = data\n","          images=images.to(device)\n","          labels=labels.to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs, 1)\n","          c = (predicted == labels).squeeze()\n","          for i in range(4):\n","            try:\n","              confusionMatrix[labels[i],predicted[i]]+=1\n","            except:\n","              continue\n","  confusionMatrix=pd.DataFrame(confusionMatrix,columns=['Pred '+class_names[i] for i in range(len(class_names))],index=['Actual '+class_names[i] for i in range(len(class_names))])\n","  time_elapsed = time.time() - since\n","  print('{} completed in {:.0f}m {:.0f}s'.format(data,time_elapsed // 60, time_elapsed % 60))\n","  return confusionMatrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsAL621CJlXQ"},"source":["import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","\n","Net = Net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer_ft = optim.SGD(Net.parameters(), lr=0.001, momentum=0.9)\n","#optimizer_ft = optim.SGD(Net.parameters(), lr=0.005, momentum=0.9)\n","#optimizer_ft = optim.Adam(Net.parameters(),lr=0.0005)\n","\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUmavuL_JpLR"},"source":["try:\n","  del model_ft\n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgvZKkyoYgnF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618993971361,"user_tz":-330,"elapsed":143579,"user":{"displayName":"Dwijesh Athrey K","photoUrl":"","userId":"01879196924165953212"}},"outputId":"00bcb195-491e-4411-dd40-389877044c8f"},"source":["model_ft = train_model(Net, criterion, optimizer_ft, exp_lr_scheduler,\n","                       num_epochs=25)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0/24\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["train Running Corrects:,4987.0\n","train Loss: 1.5335 Acc: 0.4656\n","val Running Corrects:,1554.0\n","val Loss: 1.1197 Acc: 0.5803\n","\n","Epoch 1/24\n","----------\n","train Running Corrects:,6267.0\n","train Loss: 1.1479 Acc: 0.5852\n","val Running Corrects:,1685.0\n","val Loss: 1.0331 Acc: 0.6292\n","\n","Epoch 2/24\n","----------\n","train Running Corrects:,6687.0\n","train Loss: 1.0478 Acc: 0.6244\n","val Running Corrects:,1781.0\n","val Loss: 0.9292 Acc: 0.6650\n","\n","Epoch 3/24\n","----------\n","train Running Corrects:,6903.0\n","train Loss: 0.9698 Acc: 0.6445\n","val Running Corrects:,1774.0\n","val Loss: 0.9217 Acc: 0.6624\n","\n","Epoch 4/24\n","----------\n","train Running Corrects:,7107.0\n","train Loss: 0.9221 Acc: 0.6636\n","val Running Corrects:,1739.0\n","val Loss: 0.9784 Acc: 0.6494\n","\n","Epoch 5/24\n","----------\n","train Running Corrects:,7317.0\n","train Loss: 0.8678 Acc: 0.6832\n","val Running Corrects:,1814.0\n","val Loss: 0.8978 Acc: 0.6774\n","\n","Epoch 6/24\n","----------\n","train Running Corrects:,8048.0\n","train Loss: 0.6850 Acc: 0.7514\n","val Running Corrects:,1910.0\n","val Loss: 0.7851 Acc: 0.7132\n","\n","Epoch 7/24\n","----------\n","train Running Corrects:,8315.0\n","train Loss: 0.6247 Acc: 0.7764\n","val Running Corrects:,1952.0\n","val Loss: 0.7679 Acc: 0.7289\n","\n","Epoch 8/24\n","----------\n","train Running Corrects:,8331.0\n","train Loss: 0.6037 Acc: 0.7779\n","val Running Corrects:,1940.0\n","val Loss: 0.7654 Acc: 0.7244\n","\n","Epoch 9/24\n","----------\n","train Running Corrects:,8474.0\n","train Loss: 0.5785 Acc: 0.7912\n","val Running Corrects:,1933.0\n","val Loss: 0.7607 Acc: 0.7218\n","\n","Epoch 10/24\n","----------\n","train Running Corrects:,8545.0\n","train Loss: 0.5598 Acc: 0.7979\n","val Running Corrects:,1956.0\n","val Loss: 0.7606 Acc: 0.7304\n","\n","Epoch 11/24\n","----------\n","train Running Corrects:,8593.0\n","train Loss: 0.5392 Acc: 0.8023\n","val Running Corrects:,1978.0\n","val Loss: 0.7486 Acc: 0.7386\n","\n","Epoch 12/24\n","----------\n","train Running Corrects:,8652.0\n","train Loss: 0.5229 Acc: 0.8078\n","val Running Corrects:,1955.0\n","val Loss: 0.7541 Acc: 0.7300\n","\n","Epoch 13/24\n","----------\n","train Running Corrects:,8796.0\n","train Loss: 0.4912 Acc: 0.8213\n","val Running Corrects:,1968.0\n","val Loss: 0.7528 Acc: 0.7349\n","\n","Epoch 14/24\n","----------\n","train Running Corrects:,8852.0\n","train Loss: 0.4796 Acc: 0.8265\n","val Running Corrects:,1971.0\n","val Loss: 0.7519 Acc: 0.7360\n","\n","Epoch 15/24\n","----------\n","train Running Corrects:,8856.0\n","train Loss: 0.4798 Acc: 0.8269\n","val Running Corrects:,1965.0\n","val Loss: 0.7515 Acc: 0.7338\n","\n","Epoch 16/24\n","----------\n","train Running Corrects:,8875.0\n","train Loss: 0.4758 Acc: 0.8287\n","val Running Corrects:,1957.0\n","val Loss: 0.7545 Acc: 0.7308\n","\n","Epoch 17/24\n","----------\n","train Running Corrects:,8918.0\n","train Loss: 0.4699 Acc: 0.8327\n","val Running Corrects:,1963.0\n","val Loss: 0.7554 Acc: 0.7330\n","\n","Epoch 18/24\n","----------\n","train Running Corrects:,8915.0\n","train Loss: 0.4644 Acc: 0.8324\n","val Running Corrects:,1963.0\n","val Loss: 0.7544 Acc: 0.7330\n","\n","Epoch 19/24\n","----------\n","train Running Corrects:,8989.0\n","train Loss: 0.4622 Acc: 0.8393\n","val Running Corrects:,1964.0\n","val Loss: 0.7558 Acc: 0.7334\n","\n","Epoch 20/24\n","----------\n","train Running Corrects:,8941.0\n","train Loss: 0.4611 Acc: 0.8348\n","val Running Corrects:,1963.0\n","val Loss: 0.7554 Acc: 0.7330\n","\n","Epoch 21/24\n","----------\n","train Running Corrects:,8946.0\n","train Loss: 0.4649 Acc: 0.8353\n","val Running Corrects:,1963.0\n","val Loss: 0.7551 Acc: 0.7330\n","\n","Epoch 22/24\n","----------\n","train Running Corrects:,8975.0\n","train Loss: 0.4579 Acc: 0.8380\n","val Running Corrects:,1963.0\n","val Loss: 0.7550 Acc: 0.7330\n","\n","Epoch 23/24\n","----------\n","train Running Corrects:,8948.0\n","train Loss: 0.4604 Acc: 0.8355\n","val Running Corrects:,1964.0\n","val Loss: 0.7549 Acc: 0.7334\n","\n","Epoch 24/24\n","----------\n","train Running Corrects:,8962.0\n","train Loss: 0.4607 Acc: 0.8368\n","val Running Corrects:,1963.0\n","val Loss: 0.7549 Acc: 0.7330\n","\n","Training complete in 103m 25s\n","Best val Acc: 0.738611\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gcmED9jMavuZ"},"source":["torch.save(model_ft.state_dict(),'CNN/VGG16_only_fl_BW_Aug.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"34CCMW7obQ2M"},"source":["model = vgg16\n","model.load_state_dict(torch.load('CNN/VGG16_only_fl_BW_Aug.pt',map_location=torch.device('cpu')))\n","model = model.to(device)\n","model.eval();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMyEx9vvcjvj"},"source":["ConfMat(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6j6DUe7NlhXv"},"source":["ConfMat(model,'train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-e4hvaKmssH"},"source":[""],"execution_count":null,"outputs":[]}]}